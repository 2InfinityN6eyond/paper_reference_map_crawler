{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11877 11877\n"
     ]
    }
   ],
   "source": [
    "#pip install selenium\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import platform\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == \"Darwin\":\n",
    "    #import undetected_chromedriver as webdriver\n",
    "    from selenium import webdriver\n",
    "\n",
    "elif os_name == \"Linux\":\n",
    "    from selenium import webdriver\n",
    "\n",
    "#from selenium import webdriver\n",
    "#import undetected_chromedriver.v2 as webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "from containers import Institution, Author, Paper, Expertise\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class JournalConference :\n",
    "    type : str = None\n",
    "    name : str = None\n",
    "    ISSN : str = None\n",
    "    eissn : str = None\n",
    "    publisher : str = None\n",
    "    URL : str = None\n",
    "    Country : str = None\n",
    "    Status : str = None\n",
    "\n",
    "\n",
    "\n",
    "PROCESSED_PAPER_FILE_PATH = \"./processed_paper_dict.json\"\n",
    "if os.path.exists(PROCESSED_PAPER_FILE_PATH) :\n",
    "    with open(PROCESSED_PAPER_FILE_PATH, \"r\") as f :\n",
    "        processed_paper_dict = json.load(f)\n",
    "for k, v in processed_paper_dict.items() :\n",
    "    processed_paper_dict[k] = Paper(**v)\n",
    "\n",
    "unique_processed_paper_dict = {}\n",
    "for k in list(set(processed_paper_dict.keys())) :\n",
    "    unique_processed_paper_dict[k] = processed_paper_dict[k]\n",
    "\n",
    "print(len(unique_processed_paper_dict), len(processed_paper_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3527/3527 [00:00<00:00, 745179.84it/s]\n"
     ]
    }
   ],
   "source": [
    "issn_list = []\n",
    "for k, v in unique_processed_paper_dict.items() :\n",
    "    issn_list += v.crossref_json[\"ISSN\"]\n",
    "issn_list = list(set(issn_list))\n",
    "\n",
    "journal_conference_dict = {}\n",
    "for issn in tqdm(issn_list) :\n",
    "    journal_conference_dict[issn] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ISSN_Crawler :\n",
    "    BASE_URL = \"https://portal.issn.org/\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            institution_dict = None,\n",
    "            expertise_dict = None,\n",
    "            os_name = None\n",
    "        ) :\n",
    "\n",
    "        if os_name == \"Darwin\":\n",
    "            self.driver = webdriver.Safari()\n",
    "            self.browser_name = \"safari\"\n",
    "        else :\n",
    "            chrome_options = webdriver.ChromeOptions()\n",
    "            #chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--use_subprocess\")\n",
    "            self.browser_name = \"chrome\"\n",
    "\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        \n",
    "    def crawl_by_issn(self, issn) :\n",
    "        '''\n",
    "        access issn portal and crawl journal/conference by issn\n",
    "        args :\n",
    "            issn : str\n",
    "        '''\n",
    "        self.driver.get(self.BASE_URL)\n",
    "        self.driver.implicitly_wait(10)\n",
    "        # find input tag with id = \"edit-keyword--2\"\n",
    "        searcher = self.driver.find_element(by=By.XPATH, value=\"//input[@id='edit-keyword--2']\")\n",
    "\n",
    "        searcher.send_keys(issn)\n",
    "        searcher.send_keys(Keys.RETURN)\n",
    "        \n",
    "        self.driver.implicitly_wait(10)\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, 10).until(self.wait_for_specific_elements)\n",
    "            # Now one of the elements is present, and you can interact with it\n",
    "            # 'element' will be either the h3 or h5 element, depending on which appeared first\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Neither element appeared within the given time.\")\n",
    "        '''\n",
    "\n",
    "        page_source = self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        failed_message_list = soup.find_all(\"h3\", class_ = \"page-title\")\n",
    "        for failed_message in failed_message_list :\n",
    "            if \"The server was unable to fulfill your request\" in failed_message.text :\n",
    "                print(\"failed to crawl : \", issn)\n",
    "                return False, None\n",
    "            \n",
    "        search_result_list =  soup.find_all(\"div\", class_ = \"item-result\")\n",
    "\n",
    "\n",
    "        jc_dict = {}\n",
    "        for search_result in search_result_list :\n",
    "            info_dict = {}\n",
    "            for i in search_result.find_all(\"p\")[:-1] :\n",
    "                info_dict[i.text.split(\":\")[0]] = i.text.split(\":\")[1]\n",
    "\n",
    "            title = search_result.find(\"h5\", class_ = \"item-result-title\").text.strip()\n",
    "            jc_dict[title] = info_dict\n",
    "\n",
    "        journalnal_conference_dict = {}\n",
    "        for k, v in jc_dict.items() :\n",
    "            if \"ISSN\" in v :\n",
    "                if issn != v[\"ISSN\"] :\n",
    "                    print(issn, v[\"ISSN\"])\n",
    "            #issn = v[\"ISSN\"]\n",
    "            title = k\n",
    "            journalnal_conference_dict[issn] = JournalConference(name = title, **v)\n",
    "\n",
    "        return True, journalnal_conference_dict\n",
    "    \n",
    "\n",
    "    def wait_for_specific_elements(self):\n",
    "        try:\n",
    "            # Trying to find the h3 with class 'page-title'\n",
    "            h3_element = self.driver.find_element(By.CSS_SELECTOR, \"h3.page-title\")\n",
    "            if h3_element:\n",
    "                return h3_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Trying to find the h5 with class 'item-result'\n",
    "            h5_element = self.driver.find_element(By.CSS_SELECTOR, \"h5.item-result\")\n",
    "            if h5_element:\n",
    "                return h5_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017-1398\n",
      "name 'WebDriverWait' is not defined\n",
      "Neither element appeared within the given time.\n"
     ]
    }
   ],
   "source": [
    "ISSN = issn_list[0]\n",
    "print(ISSN)\n",
    "\n",
    "issn_crawler = ISSN_Crawler(os_name = os_name)\n",
    "jc_dict = issn_crawler.crawl_by_issn(ISSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3531 [00:12<12:02:19, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017-1398  1017-1398\n",
      "1017-1398  1572-9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3531 [00:14<6:30:46,  6.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0929-6212  0929-6212\n",
      "0929-6212  1572-834X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3531 [00:22<4:33:28,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0021-9797  0021-9797\n",
      "0021-9797  1095-7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/3531 [00:32<3:31:38,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0022-1007  0022-1007\n",
      "0022-1007  1540-9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3531 [00:43<3:26:16,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383-469X  1383-469X\n",
      "1383-469X  1572-8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/3531 [00:50<3:11:05,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0883-2927  0883-2927\n",
      "0883-2927  1872-9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/3531 [00:52<3:03:10,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0016-5492  0016-5492\n",
      "0016-5492  1460-3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3531 [00:56<3:16:19,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0142-7164  0142-7164\n",
      "0142-7164  1469-1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3531 [00:59<3:05:56,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942-3888  1942-3888\n",
      "1942-3888  1942-3896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/3531 [01:02<3:03:52,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168-6165  2168-6165\n",
      "2168-6165  2168-6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/3531 [01:05<3:07:26,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0350-5596  0350-5596\n",
      "0350-5596  1854-3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/3531 [01:08<2:53:43,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094-2076  1094-2076\n",
      "1094-2076  2325-5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/3531 [01:11<2:57:29,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0737-8831  0737-8831\n",
      "0737-8831  2054-166X\n"
     ]
    }
   ],
   "source": [
    "issn_crawler = ISSN_Crawler()\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for issn in tqdm(journal_conference_dict.keys()) :\n",
    "    if issn in result_dict.keys() :\n",
    "        continue\n",
    "    try :\n",
    "        success, jc_dict = issn_crawler.crawl_by_issn(issn)\n",
    "    except Exception as e :\n",
    "        continue\n",
    "    if success :\n",
    "        result_dict.update(jc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISSN = \"0278-0000\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(ISSN_Crawler.BASE_URL)\n",
    "driver.implicitly_wait(10)\n",
    "# find input tag with id = \"edit-keyword--2\"\n",
    "searcher = driver.find_element(by=By.XPATH, value=\"//input[@id='edit-keyword--2']\")\n",
    "\n",
    "searcher.send_keys(ISSN)\n",
    "searcher.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "failed\n"
     ]
    }
   ],
   "source": [
    "failed_message_list = soup.find_all(\"h3\", class_ = \"page-title\")\n",
    "for failed_message in failed_message_list :\n",
    "    if \"The server was unable to fulfill your request\" in failed_message.text :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result_list =  soup.find_all(\"div\", class_ = \"item-result\")\n",
    "\n",
    "jc_dict = {}\n",
    "for search_result in search_result_list :\n",
    "    info_dict = {}\n",
    "    for i in search_result.find_all(\"p\")[:-1] :\n",
    "        info_dict[i.text.split(\":\")[0]] = i.text.split(\":\")[1]\n",
    "\n",
    "    title = search_result.find(\"h5\", class_ = \"item-result-title\").text.strip()\n",
    "    jc_dict[title] = info_dict\n",
    "jc_dict\n",
    "\n",
    "journalnal_conference_dict = {}\n",
    "for k, v in jc_dict.items() :\n",
    "    issn = v[\"ISSN\"]\n",
    "    title = k\n",
    "    journalnal_conference_dict[issn] = JournalConference(name = title, **v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journalnal_conference_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Journal of accounting and public policy (Print)', 'Journal of accounting and public policy (Online)'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ISSN': '1873-2070', 'Country': 'Netherlands', 'Status': 'Confirmed'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infor = {}\n",
    "for i in info[:-1] :\n",
    "    infor[i.text.split(\": \")[0]] = i.text.split(\": \")[1]\n",
    "infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISSN: 1873-2070'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<input class=\"input-main-search form-text required\" id=\"edit-keyword\" maxlength=\"400\" name=\"keyword\" placeholder=\"Type an ISSN or a title\" size=\"400\" type=\"text\" value=\"\"/>,\n",
       " <input class=\"input-main-search form-text required\" id=\"edit-keyword--2\" maxlength=\"400\" name=\"keyword\" placeholder=\"Type an ISSN or a title\" size=\"400\" type=\"text\" value=\"\"/>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"input\", class_=\"input-main-search form-text required\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
