{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11877 11877\n"
     ]
    }
   ],
   "source": [
    "#pip install selenium\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import platform\n",
    "from pprint import pprint\n",
    "\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == \"Darwin\":\n",
    "    #import undetected_chromedriver as webdriver\n",
    "    from selenium import webdriver\n",
    "\n",
    "elif os_name == \"Linux\":\n",
    "    from selenium import webdriver\n",
    "\n",
    "#from selenium import webdriver\n",
    "#import undetected_chromedriver.v2 as webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "from containers import Institution, Author, Paper, Expertise\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class JournalConference :\n",
    "    type : str = None\n",
    "    name : str = None\n",
    "    ISSN : str = None\n",
    "    eissn : str = None\n",
    "    publisher : str = None\n",
    "    URL : str = None\n",
    "    Country : str = None\n",
    "    Status : str = None\n",
    "    url_list : list = None\n",
    "\n",
    "    def toJSON(self) :\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=4)\n",
    "    def toDict(self) :\n",
    "        return json.loads(self.toJSON())\n",
    "\n",
    "\n",
    "class ISSN_Crawler :\n",
    "    BASE_URL = \"https://portal.issn.org/\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            institution_dict = None,\n",
    "            expertise_dict = None,\n",
    "            os_name = None\n",
    "        ) :\n",
    "\n",
    "        if os_name == \"Darwin\":\n",
    "            self.driver = webdriver.Safari()\n",
    "            self.browser_name = \"safari\"\n",
    "        else :\n",
    "            chrome_options = webdriver.ChromeOptions()\n",
    "            #chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--use_subprocess\")\n",
    "            self.browser_name = \"chrome\"\n",
    "\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        \n",
    "    def crawl_by_issn(self, issn) :\n",
    "        '''\n",
    "        access issn portal and crawl journal/conference by issn\n",
    "        args :\n",
    "            issn : str\n",
    "        '''\n",
    "        self.driver.get(self.BASE_URL)\n",
    "        self.driver.implicitly_wait(10)\n",
    "        # find input tag with id = \"edit-keyword--2\"\n",
    "        searcher = self.driver.find_element(by=By.XPATH, value=\"//input[@id='edit-keyword--2']\")\n",
    "\n",
    "        searcher.send_keys(issn)\n",
    "        searcher.send_keys(Keys.RETURN)\n",
    "        \n",
    "        self.driver.implicitly_wait(10)\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, 10).until(self.wait_for_specific_elements)\n",
    "            # Now one of the elements is present, and you can interact with it\n",
    "            # 'element' will be either the h3 or h5 element, depending on which appeared first\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Neither element appeared within the given time.\")\n",
    "        '''\n",
    "\n",
    "        page_source = self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        failed_message_list = soup.find_all(\"h3\", class_ = \"page-title\")\n",
    "        for failed_message in failed_message_list :\n",
    "            if \"The server was unable to fulfill your request\" in failed_message.text :\n",
    "                print(\"failed to crawl : \", issn)\n",
    "                return False, None\n",
    "            \n",
    "        search_result_list =  soup.find_all(\"div\", class_ = \"item-result\")\n",
    "\n",
    "        jc_dict = {}\n",
    "        for search_result in search_result_list :\n",
    "            info_dict = {\"url_list\": []}\n",
    "            for i in search_result.find_all(\"p\")[:-1] :\n",
    "                info_dict[i.text.split(\":\")[0]] = i.text.split(\":\")[1]\n",
    "                url_list = []\n",
    "                href_list = i.find_all(\"a\")\n",
    "                if len(href_list) > 0 :\n",
    "                    for href in href_list :\n",
    "                        url_list.append(href[\"href\"])\n",
    "                \n",
    "                info_dict[\"url_list\"] += url_list\n",
    "\n",
    "            title = search_result.find(\"h5\", class_ = \"item-result-title\").text.strip()\n",
    "            jc_dict[title] = info_dict\n",
    "\n",
    "        journalnal_conference_dict = {}\n",
    "        for k, v in jc_dict.items() :\n",
    "            #issn = v[\"ISSN\"]\n",
    "            title = k\n",
    "            journalnal_conference_dict[issn] = JournalConference(name = title, **v)\n",
    "\n",
    "        return True, journalnal_conference_dict\n",
    "    \n",
    "    def wait_for_specific_elements(self):\n",
    "        try:\n",
    "            # Trying to find the h3 with class 'page-title'\n",
    "            h3_element = self.driver.find_element(By.CSS_SELECTOR, \"h3.page-title\")\n",
    "            if h3_element:\n",
    "                return h3_element\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Trying to find the h5 with class 'item-result'\n",
    "            h5_element = self.driver.find_element(By.CSS_SELECTOR, \"h5.item-result\")\n",
    "            if h5_element:\n",
    "                return h5_element\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "\n",
    "PROCESSED_PAPER_FILE_PATH = \"./processed_paper_dict.json\"\n",
    "if os.path.exists(PROCESSED_PAPER_FILE_PATH) :\n",
    "    with open(PROCESSED_PAPER_FILE_PATH, \"r\") as f :\n",
    "        processed_paper_dict = json.load(f)\n",
    "for k, v in processed_paper_dict.items() :\n",
    "    processed_paper_dict[k] = Paper(**v)\n",
    "\n",
    "unique_processed_paper_dict = {}\n",
    "for k in list(set(processed_paper_dict.keys())) :\n",
    "    unique_processed_paper_dict[k] = processed_paper_dict[k]\n",
    "\n",
    "print(len(unique_processed_paper_dict), len(processed_paper_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "issn_list = []\n",
    "for k, v in unique_processed_paper_dict.items() :\n",
    "    issn_list += v.crossref_json[\"ISSN\"]\n",
    "issn_list = sorted(list(set(issn_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3527 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "issn_crawler = ISSN_Crawler()\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for issn in tqdm(issn_list) :\n",
    "    if issn in result_dict.keys() :\n",
    "        continue\n",
    "    try :\n",
    "        success, jc_dict = issn_crawler.crawl_by_issn(issn)\n",
    "    except Exception as e :\n",
    "        continue\n",
    "    if success :\n",
    "        result_dict.update(jc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0001-0782': JournalConference(type=None,\n",
      "                                name='Communications of the ACM (Online)',\n",
      "                                ISSN=' 1557-7317',\n",
      "                                eissn=None,\n",
      "                                publisher=None,\n",
      "                                URL=' books.google.com/books?id ... ',\n",
      "                                Country=' United States',\n",
      "                                Status=' Confirmed',\n",
      "                                url_list=['http://books.google.com/books?id=HT5VAAAAMAAJ']),\n",
      " '0001-1541': JournalConference(type=None,\n",
      "                                name='AIChE journal (Online)',\n",
      "                                ISSN=' 1547-5905',\n",
      "                                eissn=None,\n",
      "                                publisher=None,\n",
      "                                URL=' www.sciencedirect.com/sci ... ',\n",
      "                                Country=' United States',\n",
      "                                Status=' Confirmed',\n",
      "                                url_list=['http://www.sciencedirect.com/science/journal/00011541']),\n",
      " '0001-2092': JournalConference(type=None,\n",
      "                                name='AORN journal (Online)',\n",
      "                                ISSN=' 1878-0369',\n",
      "                                eissn=None,\n",
      "                                publisher=None,\n",
      "                                URL=' www.sciencedirect.com/sci ... ',\n",
      "                                Country=' Netherlands',\n",
      "                                Status=' Confirmed',\n",
      "                                url_list=['http://www.sciencedirect.com/science/journal/00012092']),\n",
      " '0001-4826': JournalConference(type=None,\n",
      "                                name='The accounting review (Online)',\n",
      "                                ISSN=' 1558-7967',\n",
      "                                eissn=None,\n",
      "                                publisher=None,\n",
      "                                URL=' aaahq.org/ic/browse.htm',\n",
      "                                Country=' United States',\n",
      "                                Status=' Confirmed',\n",
      "                                url_list=['http://aaahq.org/ic/browse.htm'])}\n"
     ]
    }
   ],
   "source": [
    "pprint(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_conference_dict_dict = {}\n",
    "for k, v in result_dict.items() :\n",
    "    journal_conference_dict_dict[k] = v.__dict__\n",
    "with open(\"journal_conference_dict.json\", \"w\") as f :\n",
    "    json.dump(journal_conference_dict_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISSN = \"0028-1298\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(ISSN_Crawler.BASE_URL)\n",
    "driver.implicitly_wait(10)\n",
    "# find input tag with id = \"edit-keyword--2\"\n",
    "searcher = driver.find_element(by=By.XPATH, value=\"//input[@id='edit-keyword--2']\")\n",
    "\n",
    "searcher.send_keys(ISSN)\n",
    "searcher.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_message_list = soup.find_all(\"h3\", class_ = \"page-title\")\n",
    "for failed_message in failed_message_list :\n",
    "    if \"The server was unable to fulfill your request\" in failed_message.text :\n",
    "        print(\"failed to crawl : \", ISSN)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.springerlink.com/content/100530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{' 0028-1298': JournalConference(type=None, name=\"Naunyn-Schmiedeberg's archives of pharmacology\", ISSN=' 0028-1298', eissn=None, publisher=None, URL=None, Country=' Germany', Status=' Confirmed'),\n",
       " ' 1432-1912': JournalConference(type=None, name=\"Naunyn-Schmiedeberg's archives of pharmacology (Internet)\", ISSN=' 1432-1912', eissn=None, publisher=None, URL=' www.springerlink.com/cont ... ', Country=' Germany', Status=' Confirmed')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_result_list =  soup.find_all(\"div\", class_ = \"item-result\")\n",
    "\n",
    "jc_dict = {}\n",
    "for search_result in search_result_list :\n",
    "    info_dict = {}\n",
    "    for i in search_result.find_all(\"p\")[:-1] :\n",
    "        info_dict[i.text.split(\":\")[0]] = i.text.split(\":\")[1]\n",
    "        url_list = []\n",
    "        href_list = i.find_all(\"a\")\n",
    "        if len(href_list) > 0 :\n",
    "            for href in href_list :\n",
    "                url_list.append(href[\"href\"])\n",
    "\n",
    "    title = search_result.find(\"h5\", class_ = \"item-result-title\").text.strip()\n",
    "    jc_dict[title] = info_dict\n",
    "\n",
    "journalnal_conference_dict = {}\n",
    "for k, v in jc_dict.items() :\n",
    "    issn = v[\"ISSN\"]\n",
    "    title = k\n",
    "    journalnal_conference_dict[issn] = JournalConference(name = title, **v)\n",
    "\n",
    "journalnal_conference_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journalnal_conference_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Journal of accounting and public policy (Print)', 'Journal of accounting and public policy (Online)'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ISSN': '1873-2070', 'Country': 'Netherlands', 'Status': 'Confirmed'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infor = {}\n",
    "for i in info[:-1] :\n",
    "    infor[i.text.split(\": \")[0]] = i.text.split(\": \")[1]\n",
    "infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISSN: 1873-2070'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<input class=\"input-main-search form-text required\" id=\"edit-keyword\" maxlength=\"400\" name=\"keyword\" placeholder=\"Type an ISSN or a title\" size=\"400\" type=\"text\" value=\"\"/>,\n",
       " <input class=\"input-main-search form-text required\" id=\"edit-keyword--2\" maxlength=\"400\" name=\"keyword\" placeholder=\"Type an ISSN or a title\" size=\"400\" type=\"text\" value=\"\"/>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"input\", class_=\"input-main-search form-text required\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
