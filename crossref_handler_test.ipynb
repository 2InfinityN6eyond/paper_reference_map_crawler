{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import urllib.parse\n",
    "import concurrent.futures\n",
    "\n",
    "from containers import Paper, Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossRefFetcher :\n",
    "    def __init__(self) :\n",
    "        pass\n",
    "\n",
    "    def fetchMetaDatafromTitle(self, paper) :\n",
    "        '''\n",
    "        args :\n",
    "            paper : Paper\n",
    "                expect paper.title\n",
    "        '''\n",
    "        title = urllib.parse.quote(paper.title)\n",
    "        url = f'https://api.crossref.org/works?query.bibliographic={title}&rows=1'\n",
    "\n",
    "        try :\n",
    "            r = requests.get(url)\n",
    "            metadata = r.json()['message']['items'][0]\n",
    "            if len(metadata) == 0 :\n",
    "                paper.DOI = False\n",
    "                paper.reference_list = False\n",
    "                return None\n",
    "            reference_list = []\n",
    "            try :\n",
    "                paper.DOI = metadata['DOI']\n",
    "                for reference in metadata['reference'] :\n",
    "                    if 'DOI' in reference :\n",
    "                        reference_list.append(reference['DOI'])\n",
    "            except :\n",
    "                pass\n",
    "            paper.crossref_json = metadata\n",
    "            paper.reference_list = reference_list\n",
    "        \n",
    "        except Exception as e :\n",
    "            paper.DOI = False\n",
    "            paper.crossref_json = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole paper dict size : 15005, paper to process : 10587\n"
     ]
    }
   ],
   "source": [
    "whole_author_list = []\n",
    "whole_paper_dict = {}\n",
    "\n",
    "AUTHOR_FILE_PATH = \"./author_list.json\"\n",
    "if os.path.exists(AUTHOR_FILE_PATH) :\n",
    "    with open(AUTHOR_FILE_PATH, \"r\") as f :\n",
    "        author_list_raw = json.load(f)\n",
    "    for author in author_list_raw :\n",
    "        whole_author_list.append(Author(**author))\n",
    "\n",
    "WHOLE_PAPER_FILE_PATH = \"./whole_paper_dict.json\"\n",
    "if os.path.exists(WHOLE_PAPER_FILE_PATH) :\n",
    "    with open(WHOLE_PAPER_FILE_PATH, \"r\") as f :\n",
    "        whole_paper_dict = json.load(f)\n",
    "    for k, v in whole_paper_dict.items() :\n",
    "        whole_paper_dict[k] = Paper(**v)\n",
    "\n",
    "PROCESSED_PAPER_FILE_PATH = \"./processed_paper_dict.json\"\n",
    "if os.path.exists(PROCESSED_PAPER_FILE_PATH) :\n",
    "    with open(PROCESSED_PAPER_FILE_PATH, \"r\") as f :\n",
    "        processed_paper_dict = json.load(f)\n",
    "    for k, v in processed_paper_dict.items() :\n",
    "        processed_paper_dict[k] = Paper(**v)\n",
    "\n",
    "def checkAlreadyProcessed(key) :\n",
    "    return (    \n",
    "        key in processed_paper_dict\n",
    "    ) and (\n",
    "        processed_paper_dict[key].DOI is not False\n",
    "    ) and (\n",
    "        processed_paper_dict[key].DOI is not None\n",
    "    )\n",
    "\n",
    "# remove redundancy in whole_paper_dict\n",
    "unique_whole_paper_dict = {}\n",
    "for k, v in whole_paper_dict.items() :\n",
    "    if k not in unique_whole_paper_dict :\n",
    "        unique_whole_paper_dict[k] = v\n",
    "        \n",
    "paper_to_process_keys_list = list(filter(\n",
    "    lambda key : not checkAlreadyProcessed(key),\n",
    "    unique_whole_paper_dict.keys()\n",
    "))\n",
    "\n",
    "print(f\"whole paper dict size : {len(whole_paper_dict)}, paper to process : {len(paper_to_process_keys_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10587/10587 [22:41<00:00,  7.78it/s] \n"
     ]
    }
   ],
   "source": [
    "crossref_fetcher = CrossRefFetcher()\n",
    "\n",
    "max_threads = 30\n",
    "\n",
    "def process_paper(key) :\n",
    "    paper = whole_paper_dict[key]\n",
    "    crossref_fetcher.fetchMetaDatafromTitle(paper)\n",
    "\n",
    "# Using ThreadPoolExecutor to parallelize the task\n",
    "with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "    # Map each paper processing task to the executor\n",
    "    list(tqdm(\n",
    "        executor.map(process_paper, paper_to_process_keys_list),\n",
    "        total=len(paper_to_process_keys_list)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open processed paper dict, merge, and save\n",
    "with open(PROCESSED_PAPER_FILE_PATH, \"r\") as f :\n",
    "    processed_paper_dict = json.load(f)\n",
    "for k, v in processed_paper_dict.items() :\n",
    "    processed_paper_dict[k] = Paper(**v)\n",
    "for k in paper_to_process_keys_list :\n",
    "    processed_paper_dict[k] = whole_paper_dict[k]\n",
    "\n",
    "failed_paper_dict = {}\n",
    "\n",
    "unique_processed_paper_dict = {}\n",
    "for k, v in processed_paper_dict.items() :\n",
    "    if (\n",
    "        k not in unique_processed_paper_dict\n",
    "    ) and (\n",
    "        v.crossref_json\n",
    "    ) and (\n",
    "        \"issn-type\" in v.crossref_json\n",
    "    ) :\n",
    "        unique_processed_paper_dict[k] = v\n",
    "    else :\n",
    "        failed_paper_dict[k] = v\n",
    "for k, v in unique_processed_paper_dict.items() :\n",
    "    unique_processed_paper_dict[k] = v.toDict()\n",
    "\n",
    "for k, v in failed_paper_dict.items() :\n",
    "    failed_paper_dict[k] = v.toDict()\n",
    "\n",
    "with open(PROCESSED_PAPER_FILE_PATH, \"w\") as f :\n",
    "    json.dump(unique_processed_paper_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"./failed_paper_dict.json\", \"w\") as f :\n",
    "    json.dump(failed_paper_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4633"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in unique_processed_paper_dict.items() :\n",
    "    if v[\"crossref_json\"] and \"issn-type\" in v[\"crossref_json\"] :\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10660"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_processed_paper_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
